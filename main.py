"""
main.py - Orquestador principal del sistema h√≠brido
"""
import asyncio
import signal
from datetime import datetime, timedelta
from config import Config
from stt_vosk import VoskSTT
from tts_piper import PiperTTS

# Importar el LLM seg√∫n configuraci√≥n
def get_llm_class():
    """Obtiene la clase LLM seg√∫n configuraci√≥n"""
    if Config.LLM_PROVIDER == "gemini":
        from llm_gemini import GeminiLLM
        return GeminiLLM
    elif Config.LLM_PROVIDER == "groq":
        from llm_groq import GroqLLM
        return GroqLLM
    elif Config.LLM_PROVIDER == "ollama":
        from llm_ollama import OllamaLLM
        return OllamaLLM
    else:
        raise ValueError(f"LLM_PROVIDER inv√°lido: {Config.LLM_PROVIDER}")


class HybridVoiceAssistant:
    """Asistente de voz h√≠brido con baja latencia"""
    
    def __init__(self, conversation_duration: int = 300):
        """
        Args:
            conversation_duration: Duraci√≥n de la conversaci√≥n en segundos (default: 5 min)
        """
        self.stt = VoskSTT()
        self.tts = PiperTTS()
        
        # Obtener LLM seg√∫n configuraci√≥n
        LLMClass = get_llm_class()
        self.llm = LLMClass()
        
        self.is_running = False
        self.conversation_start = None
        self.conversation_duration = conversation_duration
        
        # Control de interrupciones
        self.is_assistant_speaking = False
        self.interrupt_flag = asyncio.Event()
        
    async def initialize(self):
        """Inicializa todos los componentes"""
        print("üöÄ Iniciando Asistente de Voz H√≠brido...")
        print("=" * 60)
        
        # Validar configuraci√≥n
        try:
            Config.validate()
            print(f"üì° LLM Provider: {Config.LLM_PROVIDER.upper()}")
        except Exception as e:
            print(f"‚ùå Error en configuraci√≥n: {e}")
            return False
        
        # Inicializar componentes
        if not self.stt.initialize():
            return False
        
        if not self.tts.initialize():
            return False
        
        # Inicializar LLM (puede ser async para Ollama)
        llm_init = self.llm.initialize()
        if asyncio.iscoroutine(llm_init):
            if not await llm_init:
                return False
        else:
            if not llm_init:
                return False
        
        print("=" * 60)
        print("‚úÖ Todos los componentes inicializados correctamente")
        return True
    
    async def run(self):
        """Loop principal del asistente"""
        self.is_running = True
        self.conversation_start = datetime.now()
        
        print("\nüéôÔ∏è  ASISTENTE ACTIVADO")
        print("üí° Habla naturalmente, puedes interrumpir en cualquier momento")
        print(f"‚è±Ô∏è  Duraci√≥n de conversaci√≥n: {self.conversation_duration}s")
        print("-" * 60)
        
        try:
            # Mensaje de bienvenida
            await self.speak("[FELIZ] Hola Estoy lista para ayudarte. En que puedo asistirte")
            
            # Crear tareas concurrentes
            listen_task = asyncio.create_task(self.listen_loop())
            timer_task = asyncio.create_task(self.timer_loop())
            
            # Esperar a que terminen
            await asyncio.gather(listen_task, timer_task)
            
        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è  Interrumpido por usuario")
        finally:
            await self.shutdown()
    
    async def listen_loop(self):
        """Loop de escucha continua"""
        async def on_user_speech(text: str):
            # Si el asistente est√° hablando, interrumpir
            if self.is_assistant_speaking:
                print("üö´ Interrupci√≥n detectada - Deteniendo respuesta")
                self.interrupt_flag.set()
                self.tts.stop_speaking()
                await asyncio.sleep(0.3)  # Peque√±a pausa para que se detenga
            
            # Procesar el mensaje del usuario
            await self.process_user_message(text)
        
        # Iniciar escucha
        await self.stt.listen_continuous(callback=on_user_speech)
    
    async def process_user_message(self, user_text: str):
        """
        Procesa un mensaje del usuario y genera respuesta
        
        Args:
            user_text: Texto transcrito del usuario
        """
        try:
            # Resetear flag de interrupci√≥n
            self.interrupt_flag.clear()
            
            # Crear callback para chunks de TTS
            async def tts_chunk_callback(chunk: str):
                if self.interrupt_flag.is_set():
                    print("‚ö†Ô∏è  Chunk cancelado por interrupci√≥n")
                    return
                
                # Extraer emoci√≥n
                emotion, clean_text = self.llm.extract_emotion(chunk)
                
                # Detectar emociones para triggers visuales
                if emotion in ["ENOJADA", "FELIZ"]:
                    print(f"üé≠ TRIGGER VISUAL: {emotion}")
                    # Aqu√≠ puedes activar efectos visuales/video
                
                # Sintetizar y reproducir
                await self.speak(clean_text)
            
            # Obtener respuesta del LLM con chunking
            self.is_assistant_speaking = True
            await self.llm.get_response_with_chunking(
                user_text,
                chunk_callback=tts_chunk_callback
            )
            
        except Exception as e:
            print(f"‚ùå Error procesando mensaje: {e}")
        finally:
            self.is_assistant_speaking = False
    
    async def speak(self, text: str):
        """
        Reproduce un texto con TTS
        
        Args:
            text: Texto a sintetizar
        """
        self.is_assistant_speaking = True
        try:
            await self.tts.generate_and_play(text)
        finally:
            self.is_assistant_speaking = False
    
    async def timer_loop(self):
        """Loop de control de tiempo de conversaci√≥n"""
        while self.is_running:
            elapsed = (datetime.now() - self.conversation_start).seconds
            remaining = self.conversation_duration - elapsed
            
            # A√±adir presi√≥n de tiempo al LLM
            if remaining <= 30 and remaining > 25:
                self.llm.add_time_pressure(remaining)
            
            # Terminar conversaci√≥n
            if remaining <= 0:
                print("\n‚è∞ Tiempo de conversaci√≥n agotado")
                await self.speak("[NEUTRAL] Ha sido un placer hablar contigo. ¬°Hasta luego!")
                self.is_running = False
                break
            
            # Mostrar tiempo restante cada minuto
            if remaining % 60 == 0:
                print(f"‚è±Ô∏è  Tiempo restante: {remaining // 60} minutos")
            
            await asyncio.sleep(1)
    
    async def shutdown(self):
        """Limpia recursos y apaga el asistente"""
        print("\nüõë Apagando asistente...")
        
        self.is_running = False
        self.stt.stop_listening()
        self.tts.stop_speaking()
        
        # Dar tiempo para que se detengan los procesos
        await asyncio.sleep(0.5)
        
        self.stt.cleanup()
        self.tts.cleanup()
        
        print("üëã Asistente apagado correctamente")


async def main():
    """Funci√≥n principal"""
    assistant = HybridVoiceAssistant(conversation_duration=300)  # 5 minutos
    
    if not await assistant.initialize():
        print("‚ùå No se pudo inicializar el asistente")
        return
    # Manejar se√±al de interrupci√≥n
    try:
        await assistant.run()
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Interrumpido por usuario (Ctrl+C)")
        await assistant.shutdown()

    # Manejar se√±al de interrupci√≥n
    """ loop = asyncio.get_running_loop()
    
    def signal_handler():
        print("\n‚ö†Ô∏è  Se√±al de interrupci√≥n recibida")
        assistant.is_running = False
    
    for sig in (signal.SIGINT, signal.SIGTERM):
        loop.add_signal_handler(sig, signal_handler)
    
    # Ejecutar asistente
    await assistant.run()"""


if __name__ == "__main__":
    print("""
    ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
    ‚ïë                                                          ‚ïë
    ‚ïë        üéôÔ∏è  ASISTENTE DE VOZ H√çBRIDO ü§ñ                  ‚ïë
    ‚ïë                                                          ‚ïë
    ‚ïë    Modelo de Baja Latencia con Inteligencia en Nube    ‚ïë
    ‚ïë                                                          ‚ïë
    ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    asyncio.run(main())